system:
  mode: "historical"
  random_seed: 123
  num_parallel_envs: 4
  log_level: "INFO"

data:
  historical:
    data_path: "data/sample_orderbook.csv"
    train_test_split: 0.8
    feature_columns:
      - "bid_price_1"
      - "bid_size_1"
      - "ask_price_1"
      - "ask_size_1"
      - "bid_price_2"
      - "bid_size_2"
      - "ask_price_2"
      - "ask_size_2"
    timestamp_column: "timestamp"
    normalize_features: true

simulation:
  max_steps_per_episode: 100
  warmup_steps: 10
  tick_size: 0.01
  initial_capital: 10000.0
  transaction_fee_pct: 0.0005
  slippage_model: "fixed"
  slippage_value: 0.0001

agents:
  num_agents: 1
  shared_policy: false
  observation_space:
    type: "Box"
    low: -10.0
    high: 10.0
    shape: [9]  # 8 features + 1 position
  action_space:
    type: "Discrete"
    n: 3  # 0: hold, 1: buy, 2: sell
  positions:
    max_position: 1
    min_position: -1


rl:
  algorithm: "PPO"
  policy_type: "MlpPolicy"
  learning_rate: 0.0003
  n_steps: 256
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  normalize_advantage: true
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: false
  sde_sample_freq: -1
  target_kl: null
  tensorboard_log: "./logs/"
  create_eval_env: true
  verbose: 1
  device: "auto"
  reward_type: simple_pnl

backtesting:
  metrics:
    - "sharpe_ratio"
    - "sortino_ratio"
    - "max_drawdown"
    - "total_pnl"
    - "win_rate"
  results_dir: "./results"
  plot_results: true